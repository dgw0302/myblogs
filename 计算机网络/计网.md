---
title: 计算机网络
categories:
- 操作系统or网络
tags:
- 计网
abbrlink: 56288
date: 2022-06-16 19:54:20
cover : https://pic1.zhimg.com/v2-7d4702713dd772b56baa6efd0c29c04c_r.jpg
---







小林coding：https://xiaolincoding.com/

六十二问：https://mp.weixin.qq.com/s/yAlErlC09GnjaVvwUo3Acg



·

# 计网前置知识

![image-20220531161314740](../../images/%E8%AE%A1%E7%BD%91/image-20220531161314740-16556250689102.png)





## OSI七层模型

|   对应层   |                作用                | 传输形式 |       协议/硬件        |
| :--------: | :--------------------------------: | :------: | :--------------------: |
|   应用层   |            提供用户服务            |   报文   | http、https、ftp、SMTP |
|   表示层   | 对数据的进行**格式转换**、**加密** |   报文   |                        |
|   会话层   |            管理通信会话            |   报文   |                        |
|   传输层   |      管理点到点的可靠数据传输      |  数据段  |        TCP、UDP        |
|   网络层   |   进行**路由选择**，决定传输路径   |  数据报  |  IP、ICMP、ARP、RARP   |
| 数据链路层 |     管理相邻两个设备之间的通信     |    帧    |                        |
|   物理层   |       提供数据传输的**介质**       |  比特流  |     中继器、集线器     |



## MAC地址与IP地址

**MAC地址**：6B(48bit)，十六进制表示，是网络上每个设备不同**接口**的唯一标识，在**数据链路层封装**。

**IP地址**：4B(32bit)，点分十进制表示，是网络跟主机的唯一标识，在**网络层封装**。



> 数据包转发过程中，源IP地址和目的IP地址不变，而源MAC地址和目的MAC地址逐跳改变。



> MAC地址是物理地址，在网卡上，电脑一出生就有，IP地址有点像逻辑地址，跟所处的局域网与MAC地址有关系。



## ARP地址解析协议

**ARP**：可以通过IP地址获取到对应设备的MAC地址。（连接IP跟MAC的桥梁）

> 1. 首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。
> 2. 当源主机需要将一个数据包要发送到目的主机时，会首先检查自己的 ARP 列表，是否存在该 IP 地址对应的 MAC 地址；如果有﹐就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。此 ARP 请求的数据包里，包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。
> 3. 网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同，就会忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址。
> 4. 源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。





##  ping 的原理

https://mp.weixin.qq.com/s/yAlErlC09GnjaVvwUo3Acg







## 路由器与交换机



交换机是用来连接局域网的，路由器是用来连接互联网的（也可以连接多个局域网）



- 交换机用于连接局域网，数据包在局域网内网的数据转发，路由器用于连接局域网和外网，数据包可以在不同局域网转发。

- 交换机工作于TCP/IP协议的最后一层数据链路层（物理层），路由器工作于网络层

- 交换机负责具体的数据包传输，路由器不负责包的实际传输，路由器只封装好要传输的数据包，然后交给交换机去传输（不一定是交换机，可能是其他传输技术），用java比喻大概简单理解为路由器是抽象类，定义好传输的数据包格式，交换机是具体实现类，也可以有其他实现类

- 交换机没有MAC地址和IP地址，路由器有MAC地址和IP地址（指纯碎的交换机和路由器，三层交换机是可以有IP地址的，路由器也有内置交换机功能的）

- 路由器工作在网络层，交换机工作在数据链路层

  

交换机：**过滤，转发（**依靠 **MAC 地址**），路由器：**寻址，转发**（依靠 **IP 地址**），











## TCP字节流UDP数据报模式

TCP是基于字节流的流式传输

UDP是基于数据报模式的一个数据包一个数据包的传输



**详细：**

udp面向数据报，每次传输都是一个一个数据包交付，不合并也不拆分，向下向上只是加首部和去首部的区别；
二tcp是面向字节流的，简单说就是，应用程序和tcp交互每次一个数据块，但tcp只把这些看做是字节流，它不保证接受方收到的数据快的大小和发送方一样，比如发送方发了10个数据块给tcp但是但接收方的tcp可能只用了5个数据块就把收到的字节流交付给自己上方的应用程序了。
总：只保证字节流大小一致，不保证数据块。因为tcp发送时要考虑对方给出的窗口值和网络拥塞情况界定发送的块的大小，言简意赅就是：大了我分块发送，少了我可以累积在一起在发送。保证你接收方收到的字节流和发送方发出的字节流一样就行。







## TCP连接一个IP或端口不存在的主机时，会发生什么？（重点）

https://blog.csdn.net/thinpikachu/article/details/120614491



![image-20220828165153413](../../images/%E8%AE%A1%E7%BD%91/image-20220828165153413.png)





连接IP存在但是端口号不存在的主机时候，主机的传输层在收到握手消息后







# TCP UDP

详细内容看https://xiaolincoding.com/network

![图片](../../images/%E8%AE%A1%E7%BD%91/640-16556238069686.png)

TCP面向连接，UDP面向无连接的。

TCP是可靠的，UDP不可靠。

TCP只支持点到点服务，UDP支持单播与广播（一对一和一对多，广播是指多个客户端和一个服务端通信）。

TCP基于字节流传输，UDP是一个一个包发送，可能会发生丢包或者乱序（TCP不会发生乱序）



## UDP如何可靠传输

**简书**：https://www.jianshu.com/p/6c73a4585eba



**小林coding**(强推):https://xiaolincoding.com/network/3_tcp/quic.html#quic-%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E7%9A%84



### UDP协议为什么不可靠



> UDP在传输数据之前不需要先建立连接，远地主机的运输层在接收到UDP报文后，不需要确认，提供不可靠交付。总结就以下四点：
>
> - 不保证消息交付：不确认，不重传，无超时
> - 不保证交付顺序：不设置包序号，不重排，不会发生队首阻塞
> - 不跟踪连接状态：不必建立连接或重启状态机
> - 不进行拥塞控制：不内置客户端或网络反馈机制





## TCP报文段



**首部格式如下**

![TCP 包头格式](../../images/%E8%AE%A1%E7%BD%91/8-16556250689103.jpg)









## 三次握手

![图片](../../images/%E8%AE%A1%E7%BD%91/640-16556186309343.png)



三次握手过程

> - 最开始，客户端和服务端都处于CLOSE状态，服务端监听客户端的请求，进入LISTEN状态
>
> - 客户端端发送连接请求，**第一次握手** (SYN=1, seq=x)，发送完毕后，客户端就进入 SYN_SENT 状态
> - 服务端确认连接，**第二次握手** (SYN=1, ACK=1, seq=y, ACKnum=x+1)， 发送完毕后，服务器端就进入 SYN_RCV 状态。
> - 客户端收到服务端的确认之后，再次向服务端确认，这就是**第三次握手 **(ACK=1，ACKnum=y+1)，发送完毕后，客户端进入 ESTABLISHED 状态，当服务器端接收到这个包时，也进入 ESTABLISHED 状态。







为什么两次不行，四次不行；

**两次不行：**

- 为了防止服务器端开启一些无用的连接增加服务器开销

- 防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。

  

**四次不行**

假如是四次，第二次和第三次（ack + syn）可以节省一起发送，避免发送两次报文。

简单说，就是三次挥手已经足够创建可靠的连接，没有必要再多一次握手导致花费更多的时间建立连接。



### 没收到报文

> - 第一次握手服务端未收到SYN报文
>
>   服务端不会进行任何的动作，而客户端由于一段时间内没有收到服务端发来的确认报文，等待一段时间后会重新发送SYN报文，如果仍然没有回应，会重复这个过程，直到发送次数超过最大重传次数限制，就会返回连接建立失败。
>
> - 第二次握手客户端未收到服务端响应的ACK报文
>
>   客户端会继续重传，直到次数限制；而服务端此时会阻塞在accept()处，等待客户端发送ACK报文
>
> - 第三次握手服务端未收到客户端发送过来的ACK报文
>
>   服务端同样会采用类似客户端的超时重传机制，如果重试次数超过限制，则accept()调用返回-1，服务端建立连接失败；而此时客户端认为自己已经建立连接成功，因此开始向服务端发送数据，但是服务端的accept()系统调用已经返回，此时不在监听状态，因此服务端接收到客户端发送来的数据时会发送RST报文给客户端，消除客户端单方面建立连接的状态。





> ### 第二次握手传回了 ACK，为什么还要传回 SYN？
>
> ACK是为了告诉客户端传来的数据已经接收无误。
>
> 而传回SYN是为了告诉客户端，服务端响应的确实是客户端发送的报文。







### **第三次握手可以携带数据**

1. 此时客户端已经处于ESTABLISHED状态。对于客户端来说，它已经建立连接成功，并且确认服务端的接收和发送能力是正常的。
2. 第一次握手不能携带数据是出于安全的考虑，因为如果允许携带数据，攻击者每次在SYN报文中携带大量数据，就会导致服务端消耗更多的时间和空间去处理这些报文，会造成CPU和内存的消耗。



### 半连接队列-SYN洪范攻击

TCP 进入三次握手前，服务端会从 **CLOSED** 状态变为 **LISTEN** 状态, 同时在内部创建了两个队列：半连接队列（SYN 队列）和全连接队列（ACCEPT 队列）。

![图片](../../images/%E8%AE%A1%E7%BD%91/640-16556200700835.png)

**顾名思义，半连接队列存放的是三次握手未完成的连接，全连接队列存放的是完成三次握手的连接。**

> TCP 三次握手时，客户端发送 SYN 到服务端，服务端收到之后，便回复 **ACK 和 SYN**，状态由 **LISTEN 变为 SYN_RCVD**，此时这个连接就被推入了 **SYN 队列**，即半连接队列。
>
> 当客户端回复 ACK, 服务端接收后，三次握手就完成了。这时连接会等待被具体的应用取走，在被取走之前，它被推入 ACCEPT 队列，即全连接队列。





**SYN Flood** 是一种典型的 DDos 攻击，它在短时间内，伪造**不存在的 IP 地址**, 向服务器发送大量SYN 报文。当服务器回复 SYN+ACK 报文后，不会收到 ACK 回应报文，那么SYN队列里的连接旧不会出对队，久⽽久之就会占满服务端的 **SYN** 接收队列（半连接队列），使得服务器不能为正常⽤户服务。





















### 两次不行吗

网上搜了一下这个问题，答案有很多，回答得最多的就是我一开始的说法：“因为TCP是三次握手，所以不能是两次”。后面总算是找到一两个比较靠谱的答案：“如果客户端一开始发送的连接请求超时，并且放弃了连接。这时服务端有可能会收到那个超时的包，如果是两次握手就可建立连接，那么此时对于服务端来说连接就是成功的，操作系统会创建新的线程和分配内存来处理后面的通信，可是此时客户端都放弃连接了，不会再有通信了，白白浪费服务器资源。”







究其根源，两次握手只能确定**从 客户端 到 服务端 的网络是可达的**，但却**无法保证从 服务端 到 客户端 的网络是可达的**。因为现实网络是不可靠的，可能丢包、超时、损坏，并且数据来回所经过的路由器也可能是不一样的，所以第三次握手就是**为了确定从 服务端 到 客户端 的网络是否可达**。













因此，**要解决这种现象，最好就是在「被动发起方」发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手**。

所以，**TCP 使用三次握手建立连接的最主要原因是防止「历史连接」初始化了连接。**















**具体：小林coding**

## 四次挥手

![图片](../../images/%E8%AE%A1%E7%BD%91/640-16556202732117.png)



### 过程

> - 数据传输结束之后，通信双方都可以主动发起断开连接请求，这里假定客户端发起
> - 客户端发送释放连接报文，**第一次挥手** (FIN=1，seq=u)，发送完毕后，客户端进入 **FIN_WAIT_1** 状态。
> - 服务端发送确认报文，**第二次挥手** (ACK=1，ack=u+1,seq =v)，发送完毕后，服务器端进入 **CLOSE_WAIT** 状态，客户端接收到这个确认包之后，进入 **FIN_WAIT_2** 状态。
> - 服务端发送释放连接报文，**第三次挥手** (FIN=1，ACK1,seq=w,ack=u+1)，发送完毕后，服务器端进入 **LAST_ACK** 状态，等待来自客户端的最后一个 ACK。
> - 客户端发送确认报文，**第四次挥手** (ACK=1，seq=u+1,ack=w+1)，客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入 TIME_WAIT 状态，**等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后**，没有收到服务器端的 ACK ，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入 CLOSED 状态。服务器端接收到这个确认包之后，关闭连接，进入 CLOSED 







### 为什么要先进入TIME-WAIT状态，等待2MSL时间后才进入CLOSED状态？

为了保证服务器能收到客户端的确认应答。若A发完确认应答后直接进入CLOSED状态，那么如果该应答报文丢失，服务器等待超时后就会重新发送连接释放请求，但此时客户端已经关闭了，不会作出任何响应，此时B永远无法正常关闭。







### 为什么要等待2MSL

MSL表示数据包的最大存活时间。

若A发送的确认报文在一个MSL内还没有发到B，则B会**重新发送一个数据包**。这样一来一回的最大时间就是2MSL。

并且等待2MSL之后，可以**确保所有的数据包都已经失效**，不会对重新连接的新报文跟老报文发生冲突。





### 为什么要是四次挥手

TCP是全双工通信（即客户端和服务器端可以相互发送和接收请求），所以需要双方都确认关闭连接。



> 再来回顾下四次挥手双方发 `FIN` 包的过程，就能理解为什么需要四次了。
>
> - 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
> - 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。
>
> 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。



### CLOSE-WAIT 和 TIME-WAIT



> **CLOSE-WAIT状态有什么意义？**

服务端收到客户端关闭连接的请求并确认之后，就会进入CLOSE-WAIT状态。此时服务端可能还有一些数据没有传输完成，因此不能立即关闭连接，而CLOSE-WAIT状态就是为了保证服务端在关闭连接之前将待发送的数据处理完。



> **TIME-WAIT有什么意义？**

TIME-WAIT状态发生在第四次挥手，当客户端向服务端发送ACK确认报文后进入TIME-WAIT状态。



TCP与UDP区别

TCP为什么要三次握手不是两次或者四次握手



**序列号**：解决包乱序的问题。

**确认号**：目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决不丢包的问题。



超时重传

流量控制

拥塞控制（重点）

等等





### 为什么需要TIME_WAIT状态



TIME-WAIT 作用是**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**



**客户端在收到服务端重传的 FIN 报文时，TIME_WAIT 状态的等待时间，会重置回 2MSL。**



> 如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。
>
> 假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSED 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。

答案：

1. 可靠的终止TCP连接。让最后一条挥手报文成功发送并服务端接收·	
2. 保证让迟来的TCP报文有足够的时间被识别并丢弃。（保证让迟来的TCP报文段有足够的时间被识别和丢弃。连接结束了，网络中的延迟报文也应该被丢弃掉，以免影响立刻建立的新连接。2>）

![image-20220825202329852](../../images/%E8%AE%A1%E7%BD%91/image-20220825202329852.png)















### 四次挥手可以改为三次挥手吗







结论：当被动关闭方（上图的服务端）在 TCP 挥手过程中，「**没有数据要发送」并且「开启了 TCP 延迟确认机制（默认会开启）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。**









**延迟确认机制**





> 当发送没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。
>
> 为了解决 ACK 传输效率低问题，所以就衍生出了 **TCP 延迟确认**。
>
> TCP 延迟确认的策略：
>
> - 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方
> - 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送
> - 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK

























## TCP 是如何保证可靠性的



TCP主要提供了检验和、序列号/确认应答、超时重传、最大消息长度、滑动窗口控制等方法实现了可靠性传输。

![图片](../../images/%E8%AE%A1%E7%BD%91/640-16556250689114.png)





1. **连接管理**：TCP使用三次握手和四次挥手保证可靠地建立连接和释放连接，这里就不用多说了。

2. **校验和**：TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果接收端的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。

3. **序列号/确认应答**：TCP 给发送的每一个包进行编号，接收方会对收到的包进行应答，发送方就会知道接收方是否收到对应的包，如果发现没有收到，就会重发，这样就能保证数据的完整性。就像老师上课，会问一句，这一章听懂了吗？没听懂再讲一遍。

   ![图片](../../images/%E8%AE%A1%E7%BD%91/640-16556219088642.png)

   4.**流量控制：**TCP  连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。（TCP 利用滑动窗口实现流量控制）



​        5.**超时重传：**超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传



​		6.**拥塞控制：**如果网络非常拥堵，此时再发送数据就会加重网络负担，那么发送的数据段很可能超过了最大生存时间也没有到达接收             		方，就会产生丢包问题。为此TCP引入慢启动机制，先发出少量数据，就像探路一样，先摸清当前的网络拥堵状态后，再决定按照多		大的速度传送数据。

![图片](../../images/%E8%AE%A1%E7%BD%91/640-16556219397484.png)











































## TCP粘包原因和解决方法



https://www.cnblogs.com/bigox/p/10833462.html

UDP不存在粘包问题



**什么是粘包以及如何解决粘包**

https://blog.csdn.net/weixin_41047704/article/details/85340311



#### 原因

TCP 粘包是指：**发送方发送的若干个 数据报 被接收方接收时，被当成一个数据报来处理**。

TCP 是基于字节流的，多个数据包存储于连续的缓存中，在对数据包进行读取时由于**无法确定发送方的发送边界，**而采用某一估测值大小来进行数据读出，若双方的size不一致时就会使数据包的边界发生错位，导致读出错误的数据分包，进而曲解原始数据含义。



#### 粘包出现原因



1. 发送方粘包：发送方需要等到缓冲区满了才会发送，若连续几次发送的数据都很少，通常TCP会根据优化算法把这些数据合成一包后一次发送出去，这时出现粘包现象。

2. 接收方粘包：接收方不及时的接收，导致数据堆在一起

   

> - 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；
> - 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；
> - 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；
> - 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 > MSS。



#### 什么时候不需要考虑粘包

1. 如果每次tcp双方发送完一段数据后，就关闭连接，这样就不会出现粘包问题。
2. 如果发送数据无结构。如文件传输，这样发送方只管发送，接收方只管接收存储，也不用考虑粘包



#### 如何避免和解决粘包？

- 发送端将每个数据包封装为固定长度
- 在数据尾部增加特殊字符进行分割
- 将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小固定，且有一个字段声明内容体的大小。



## 流量控制与拥塞控制

> TCP 提供了一种机制，可以让发送端根据接收端的实际接收能力控制发送的数据量，这就是**流量控制**。
>
> 
>
> 前⾯的流量控制是避免发送⽅的数据填满接收⽅的缓存，但是并不知道整个⽹络之中发⽣了什么
>
> ⼀般来说，计算机⽹络都处在⼀个共享的环境。因此也有可能会因为其他主机之间的通信使得⽹络拥堵。
>
> 在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 **TCP** 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤....
>
> 所以，TCP 不能忽略整个网络中发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据流。
>
> 于是，就有了拥塞控制，控制的⽬的就是避免发送⽅的数据填满整个⽹络。





**拥塞窗⼝ cwnd是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。**

**发送窗⼝ swnd 和接收窗⼝ rwnd 是约等于的关系，那么由于加⼊了拥塞窗⼝的概念后，此时发送窗⼝的值是swnd = min(cwnd, rwnd)，也就是拥塞窗⼝和接收窗⼝中的最⼩值。**



1. 流量控制是避免发送⽅的数据填满接收⽅的缓存

   

2. 拥塞控制，控制的⽬的就是避免发送⽅的数据填满整个⽹络。

**滑动窗口、拥塞控制等等**

**具体****详情**：https://mp.weixin.qq.com/s/yAlErlC09GnjaVvwUo3Acg



## 超时重传与快速重传



### 超时重传

超时重传，是 TCP 协议保证数据可靠性的另一个重要机制，其原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的 ACK 报文，那么就重新发送数据，直到发送成功为止。



**超时时间应该设置为多少呢？**

**RTT（Round-Trip Time，往返时间）**：**RTT 就是数据完全发送完，到收到确认信号的时间，即数据包的一次往返时间。**

**RTO（Retransmission Timeout)**：超时重传时间





RTO怎样设置

**Jacobson / Karels 算法**。

> 1. 首先计算 SRTT（即计算平滑的 RTT）
>
> ```
> SRTT = (1 - α) * SRTT + α * RTT  //求 SRTT 的加权平均
> ```
>
> 1. 其次，计算 RTTVAR (round-trip time variation)
>
> ```
> RTTVAR = (1 - β) * RTTVAR + β * (|RTT - SRTT|) //计算 SRTT 与真实值的差距
> ```
>
> 1. 最后，得出最终的 RTO
>
> ```
> RTO = µ * SRTT + ∂ * RTTVAR  =  SRTT + 4·RTTVAR  
> ```
>
> 在 Linux 下，**α = 0.125**，**β = 0.25**， **μ = 1**，**∂ = 4**。别问这些参数是怎么来的，它们是大量实践，调出的最优参数。





**超时重传不是十分完美的重传方案，它有这些缺点：**

- 当一个报文丢失时，会等待一定的超时周期，才重传分组，增加了端到端的时延。
- 当一个报文丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。

并且，对于 TCP，如果发生一次超时重传，时间间隔下次就会加倍。



### 快速重传



TCP 还有另外⼀种快速重传（**Fast Retransmit**）机制，它不以时间为驱动，⽽是以数据驱动重传。

它不以时间驱动，而是以数据驱动。它是基于接收端的反馈信息来引发重传的。



**快速重传机制只解决了⼀个问题，就是超时时间的问题，但是它依然⾯临着另外⼀个问题。就是重传的时候，是重传之前的⼀个，还是重传所有的问题。**



> 具体：https://mp.weixin.qq.com/s/yAlErlC09GnjaVvwUo3Acg











### 快速重传















## 流量控制



**窗口大小指的是不需要等待确认应答包而可以继续发送数据包的最大值。**



​    **所谓流量控制就是让发送发送速率不要过快，让接收方来得及接收。利用滑动窗口机制就可以实施流量控制。**

​    **原理这就是运用TCP报文段中的窗口大小字段来控制，发送方的发送窗口不可以大于接收方发回的窗口大小。**

​    **考虑一种特殊的情况，就是接收方若没有缓存足够使用，就会发送零窗口大小的报文，此时发送放将发送窗口设置为0，停止发送数据。之后接收方有足够的缓存，发送了非零窗口大小的报文，但是这个报文在中途丢失的，那么发送方的发送窗口就一直为零导致死锁。**

​    **解决这个问题，TCP为每一个连接设置一个持续计时器（persistence timer）。只要TCP的一方收到对方的零窗口通知，就启动该计时器，周期性的发送一个零窗口探测报文段。对方就在确认这个报文的时候给出现在的窗口大小（注意：TCP规定，即使设置为零窗口，也必须接收以下几种报文段：零窗口探测报文段、确认报文段和携带紧急数据的报文段）。**



**当接收端的缓冲区满了，发送端接收到接收端的窗口大小为0，这个时候停止发送数据，这个时候发送端会过了超时重发的时间，发送一个窗口探测的包，此数据端仅含一个字节以获取最新的窗口大小信息。**







## 滑动窗口与拥塞窗口



### 滑动窗口

**滑动窗口是接收数据端使用的窗口大小，用来告知发送端接收端的缓存大小，以此可以控制发生端发送数据的大小，从而达到流量控制的目的。**



当接收端的缓冲区满了，发送端接收到接收端的窗口大小为0，这个时候停止发送数据，这个时候发送端会过了超时重发的时间，发送一个窗口探测的包，此数据端仅含一个字节以获取最新的窗口大小信息。





那么有了窗口，就可以指定窗口大小，窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。



### 拥塞窗口



对于数据的发送端就是拥塞窗口了，拥塞窗口不代表缓存，拥塞窗口指某一源端数据流在一个RTT内可以最多发送的数据包数。



**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。







## TCP缺点

**小林coding**









**TCP的优点**： 可靠，稳定 TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。



 **TCP的缺点**： 慢，效率低，占用系统资源高，易被攻击 TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。 而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。









UDP的优点： 快，比TCP稍安全 UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。但UDP也是无法避免攻击的，比如：UDP Flood攻击…… UDP的缺点： 不可靠，不稳定 因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。 基于上面的优缺点，那么： 什么时候应该使用TCP： 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 在日常生活中，常见使用TCP协议的应用如下： 浏览器，用的HTTP FlashFXP，用的FTP Outlook，用的POP、SMTP Putty，用的Telnet、SSH QQ文件传输 ………… 什么时候应该使用UDP： 当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 比如，日常生活中，常见使用UDP协议的应用如下： QQ语音 QQ视频 TFTP ……

有些应用场景对可靠性要求不高会用到UPD，比如长视频，要求速率







**TCP最重要的缺点就是：建立连接的延迟和队头阻塞问题。**详情小林coding











## 客户端端口可以复用吗



https://xiaolincoding.com/network/3_tcp/port.html#%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E7%AB%AF%E5%8F%A3%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%A4%8D%E4%BD%BF%E7%94%A8%E5%90%97



https://blog.csdn.net/weixin_40710708/article/details/116795880





## TCP有序性怎样保证



序列号和确认应答机制

超时重传

滑动窗口





































































## 一个 TCP 连接可以对应几个 HTTP 请求

> 1. 如果tcp连接保持长连接 Connection:keep-alive；则只要在tcp连接（默认两小时）不断开，可以一直串行发送请求，数量没有上限；
> 2. 如果tcp连接不保持长连接，Connection:close 只能发一次请求；
>
> 
>
> 
>
> 客户端可以连接的TCP连接数是最大65535，服务端只要资源（内存CPU足够）可以有无限个TCP连接。



















#  如何基于 UDP 协议实现可靠传输？

详情小林coding



**https://blog.csdn.net/pangyemeng/article/details/50387078**









## 没有listen，能否建立TCP连接



如果是两个客户端互相连接是可以建立TCP连接的，而且两者都不需要listen端口



如果是服务端没有listen,不能建立TCP连接，会回复RST报文，拒绝客户端的请求。





https://zhuanlan.zhihu.com/p/334649587









https://blog.csdn.net/ThinPikachu/article/details/120615671













# HTTP

**详情：小林coding**



HTTP 是超文本传输协议



## 状态码

![ 五大类 HTTP 状态码 ](../../images/%E8%AE%A1%E7%BD%91/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81-16556250689115.png)



> `1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。
>
> `2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。
>
> - 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
> - 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
> - 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。
>
> `3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。
>
> - 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
> - 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。
>
> 301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。
>
> - 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。
>
> `4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。
>
> - 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
> - 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
> - 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。
>
> `5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。
>
> - 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
> - 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
> - 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
> - 「**503 Service Una**





## GET与POST





> 1. 从 HTTP 报文层面来看，GET 请求将信息放在 URL，POST 将请求信息放在请求体中。这一点使得 GET  请**求携带的数据量有限**，因为 URL 本身是有长度限制的，而 POST 请求的数据存放在报文体中**，因此对大小没有限制**。而且从形式上看，GET  请求把数据放 URL 上不太安全，而 POST 请求把数据放在请求体里想比较而言安全一些。
> 2. 从数据库层面来看，**GET 符合幂等性和安全性，而 POST 请求不符合**。这个其实和 GET/POST 请求的作用有关。按照 HTTP 的约定，GET 请求用于查看信息，不会改变服务器上的信息；而 POST 请求可能用来改变服务器上的信息。正因为 GET  请求只查看信息，不改变信息，对数据库的一次或多次操作获得的结果是一致的，认为它符合幂等性。安全性是指对数据库操作没有改变数据库中的数据。
> 3. 从其他层面来看，GET 请求能够被缓存，GET 请求能够保存在浏览器的浏览记录里，GET 请求的 URL  能够保存为浏览器书签。这些都是 POST 请求所不具备的。缓存是 GET  请求被广泛应用的根本，他能够被缓存也是因为它的幂等性和安全性，除了返回结果没有其他多余的动作，因此绝大部分的 GET 请求都被 CDN  缓存起来了，大大减少了 Web 服务器的负担。
> 4. **POST：就是发送、提交。向服务器提交/发送要被处理的数据。**



### 安全且幂等

PS：

   1.这个安全不是前文提到的安全，而是HTTP协议里面所谓的安全：**所谓的「安全」是指请求方法不会「破坏」服务器上的资源。**

2. 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

![image-20220615171833878](../../images/%E8%AE%A1%E7%BD%91/image-20220615171833878-16556250689116.png)



## 报文

**HTTP请求报文**

***请求行、请求头、请求体***

```java
GET / HTTP/1.1
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)
Accept: */*
```



HTTP 请求报文的第一行叫做请求行，后面的行叫做首部行，首部行后还可以跟一个实体主体。请求首部之后有一个空行，这个空行不能省略，它用来划分首部与实体。

**请求行包含三个字段**：

- 方法字段：包括POST、GET等请方法。
- URL 字段
- HTTP 版本字段。



**HTTP响应报文**

***相应行、响应头、响应体***

```java
HTTP/1.0 200 OK
Content-Type: text/plain
Content-Length: 137582
Expires: Thu, 05 Dec 1997 16:00:00 GMT
Last-Modified: Wed, 5 August 1996 15:55:28 GMT
Server: Apache 0.84
<html>
  <body>Hello World</body>
</html>
```

HTTP 响应报文的第一行叫做**状态行**，后面的行是**首部行**，最后是**实体主体**。



## 缓存

对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。

所以，避免发送 HTTP 请求的方法就是通过**缓存技术**，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。

HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。（详情：小林coding）





## HTTP与HTTS

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- HTTP 的端口号是 80，HTTPS 的端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。



![HTTP 与 HTTPS 网络层](../../images/%E8%AE%A1%E7%BD%91/19-HTTPS%E4%B8%8EHTTP-16556250689117.png)





### 解决了哪些风险

**有哪些风险**

> 因为HTTP 是明⽂传输，存在安全上的风险：
>
> **窃听⻛险**，⽐如通信链路上可以获取通信内容，用户账号被盗。
>
> **篡改⻛险**，⽐如强制植⼊垃圾⼴告，视觉污染。
>
> **冒充⻛险**，⽐如冒充淘宝⽹站，用户金钱损失。

**HTTPS优化**

> HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议，可以很好的解决了下面的风险：
>
> - **信息加密**：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。
> - **校验机制**：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。
> - **身份证书**：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。



> - **混合加密**的方式实现信息的**机密性**，解决了窃听的风险。
> - **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。
> - 将服务器公钥放入到**数字证书**中，解决了冒充的风险。





### HTTPS加密工作流程



SSL/TLS四次握手:

1、客户端请求建立SSL链接，并向服务端发送一个随机数–Client random和客户端支持的加密方法，比如RSA公钥加密，此时是明文传输。

2、服务端回复一种客户端支持的加密方法、一个随机数–Server random、授信的服务器证书和非对称加密的公钥。

3、客户端收到服务端的回复后利用服务端的公钥，加上新的随机数–Premaster secret 通过服务端下发的公钥及加密方法进行加密，发送给服务器。

4、服务端收到客户端的回复，利用已知的加解密方式进行解密，同时利用Client random、Server random和Premaster secret通过一定的算法生成HTTP链接数据传输的对称加密key – session key。







#### 数字证书有什么





数字证书里面有非对称加密的公钥和密钥







#### 自己理解：

1. 客户端发送HTTPS请求，并发送一个随机数字，表明自己支持的加密算法（如RSA加密算法）
2. 服务端回发一个随机数字，和数字证书（含有服务器的公钥），表明自己支持的加密算法（如RSA加密算法）
3. 客户端收到服务器的回应后，校验数字证书，如果不是有效的发送错误信息，如果有效，再生成一个随机数，并要公钥加密发送给服务端，（客户端根据三个随机数生成会话密钥）
4. 这时候双方都有三个随机数，接下来用双方协商的加密算法生成以后要加密数据的会话密钥，第四次握手，服务端发送最后的信息，通知客户端表明以后都用这个会话密钥加密通信，并表示握手阶段结束。（服务端此时也有三个密钥，也生成会话密钥）





**至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。**





**详细过程**

1. 客户端发起 HTTPS 请求，连接到服务端的 443 端口。
2. 服务端有一套数字证书（证书内容有公钥、证书颁发机构、失效日期等）。
3. 服务端将自己的数字证书发送给客户端（公钥在证书里面，私钥由服务器持有）。
4. 客户端收到数字证书之后，会验证证书的合法性。如果证书验证通过，就会生成一个随机的对称密钥，用证书的公钥加密。
5. 客户端将公钥加密后的密钥发送到服务器。
6. 服务器接收到客户端发来的密文密钥之后，用自己之前保留的私钥对其进行非对称解密，解密之后就得到客户端的密钥，然后用客户端密钥对返回数据进行对称加密，酱紫传输的数据都是密文啦。
7. 服务器将加密后的密文返回到客户端。
8. 客户端收到后，用自己的密钥对其进行对称解密，得到服务器返回的数据。

![img](../../images/%E8%AE%A1%E7%BD%91/webp.webp)



客户端怎么去校验证书的合法性 --- CA机构





























### 对称加密与非对称加密



- **对称加密: 加密和解密的秘钥使用的是同一个.**
- **非对称加密: 与对称加密算法不同，非对称加密算法需要两个密钥：公开密钥（publickey）和私有密钥（privatekey）。**



> 对称加密算法: 密钥较短，破译困难，除了数据加密标准（DES），另一个对称密钥加密系统是国际数据加密算法（IDEA），它比DES的加密性好，且对计算机性能要求也没有那么高.
>
> 优点:
>
> 算法公开、计算量小、加密速度快、加密效率高
>
> 缺点:
>
> 在数据传送前，发送方和接收方必须商定好秘钥，然后 使双方都能保存好秘钥。其次如果一方的秘钥被泄露，那么加密信息也就不安全了。另外，每对用户每次使用对称加密算法时，都需要使用其他人不知道的唯一秘钥，这会使得收、发双方所拥有的钥匙数量巨大，密钥管理成为双方的负担。
>
> 常见的对称加密算法有: DES、3DES、Blowfish、IDEA、RC4、RC5、RC6 和 AES 
>
> 非对称加密算法: 公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。
>
> 非对称加密算法实现机密信息交换的基本过程是：甲方生成一对密钥并将其中的一把作为公用密钥向其它方公开；得到该公用密钥的乙方使用该密钥对机密信息进行加密后再发送给甲方；甲方再用自己保存的另一把专用密钥对加密后的信息进行解密。甲方只能用其专用密钥解密由其公用密钥加密后的任何信息。
>
> 优点:
>
> 安全
>
> 缺点:
>
> 速度较慢
>
> 常见的非对称加密算法有: RSA、ECC（移动设备用）、Diffie-Hellman、El Gamal、DSA（数字签名用）
>
> Hash算法（摘要算法）
>
> Hash算法特别的地方在于它是一种单向算法，用户可以通过hash算法对目标信息生成一段特定长度的唯一hash值，却不能通过这个hash值重新获得目标信息。因此Hash算法常用在不可还原的密码存储、信息完整性校验等。
>
> 常见的摘要算法有: MD2、MD4、MD5、HAVAL、SHA





































**加密什么的，SSL协议详看：小林coding**

**加密过程（强推**）：https://zhuanlan.zhihu.com/p/43789231





















## HTTP/1.0，1.1，2.0 的区别

关键需要记住 **HTTP/1.0** 默认是短连接，可以强制开启，HTTP/1.1 默认长连接，HTTP/2.0 采用**多路复用**。



> **HTTP/1.0**
>
> - 默认使用**短连接**，每次请求都需要建立一个 TCP 连接。它可以设置`Connection: keep-alive` 这个字段，强制开启长连接。
>
> **HTTP/1.1**
>
> - 引入了持久连接，即 TCP 连接默认不关闭，可以被多个请求复用。
> - 分块传输编码，即服务端每产生一块数据，就发送一块，用” 流模式” 取代” 缓存模式”。
> - 管道机制，即在同一个 TCP 连接里面，客户端可以同时发送多个请求。
>
> **HTTP/2.0**
>
> - 二进制协议，1.1 版本的头信息是文本（ASCII 编码），数据体可以是文本或者二进制；2.0 中，头信息和数据体都是二进制。
> - 完全多路复用，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应。
> - 报头压缩，HTTP 协议不带有状态，每次请求都必须附上所有信息。Http/2.0 引入了头信息压缩机制，使用 gzip 或 compress 压缩后再发送。
> - 服务端推送，允许服务器未经请求，主动向客户端发送资源。
> - HTTP/2 是可以在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**







## HTTP3

HTTP/3主要有两大变化，**传输层基于UDP**、使用**QUIC保证UDP可靠性**。

HTTP/2存在的一些问题，比如重传等等，都是由于TCP本身的特性导致的，所以HTTP/3在QUIC的基础上进行发展而来，QUIC（Quick UDP Connections）直译为快速UDP网络连接，底层使用UDP进行数据传输。

HTTP/3主要有这些特点：

- 使用UDP作为传输层进行通信
- 在UDP的基础上QUIC协议保证了HTTP/3的安全性，在传输的过程中就完成了TLS加密握手
- HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 **3** 次，减少了交互次数。
- QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到影响。

我们拿一张图看一下HTTP协议的变迁：

![图片](../../images/%E8%AE%A1%E7%BD%91/640-16552989547065-16556250689128.png)





 



## cookie与session

HTTP协议是无状态的，`状态`指的是什么？是客户端的状态，字面意思，就是HTTP协议中服务端不会保存客户端的任何信息。



比如当浏览器第一次发送请求给服务器时，服务器响应了；如果同个浏览器发起第二次请求给服务器时，它还是会响应，但是呢，服务器不知道你就是刚才的那个浏览器。



记录状态的两个办法：Session 和Cookie



> - Cookie 是保存在客户端的一小块文本串的数据。客户端向服务器发起请求时，服务端会向客户端发送一个 Cookie，客户端就把 Cookie 保存起来。在客户端下次向同一服务器再发起请求时，Cookie 被携带发送到服务器。服务端可以根据这个Cookie判断用户的身份和状态。
> - Session 指的就是服务器和客户端一次会话的过程。它是另一种记录客户状态的机制。不同的是cookie保存在客户端浏览器中，而session保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是session。客户端浏览器再次访问时只需要从该session中查找用户的状态。



### 区别

> - 存储位置不一样，Cookie 保存在客户端，Session 保存在服务器端。
> - 存储数据类型不一样，Cookie 只能保存ASCII，Session可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。
> - 有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般有效时间较短，客户端关闭或者 Session 超时都会失效。
> - 隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。
> - 存储大小不同， 单个Cookie保存的数据不能超过4K，Session可存储数据远高于 Cookie。



### 关联

![图片](../../images/%E8%AE%A1%E7%BD%91/640-16556250689114.png)

> - 用户第一次请求服务器时，服务器根据用户提交的信息，创建对应的 Session，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入 Cookie 中，同时 Cookie 记录此 SessionID 是属于哪个域名。
> - 当用户第二次访问服务器时，请求会自动判断此域名下是否存在 Cookie 信息，如果存在，则自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到，说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。



### **分布式环境下Session怎么处理呢？**

分布式环境下，客户端请求经过负载均衡，可能会分配到不同的服务器上，假如一个用户的请求两次没有落到同一台服务器上，那么在新的服务器上就没有记录用户状态的Session。



**可以使用Redis等分布式缓存来存储Session，在多台服务器之间共享。**



















































































# 输入URL发生了什么

**资料**：https://zhuanlan.zhihu.com/p/57895541



- **DNS 解析:将域名解析成 IP 地址**
- **TCP 连接：TCP 三次握手**
- **发送 HTTP 请求**
- **服务器处理请求并返回 HTTP 报文**
- **浏览器解析渲染页面**
- **断开连接：TCP 四次挥手**

























https://zhuanlan.zhihu.com/p/43369093

![image-20220613224220256](../../images/%E8%AE%A1%E7%BD%91/image-20220613224220256-16556250689129.png)



这个问题算是经典且重要了



**先来大体步骤：**





1. 　　浏览器缓存查找域名对应的ip
2. 　　域名解析（DNS）
3. 　　根据IP建立TCP连接（三次握手）。
4. 　　HTTP发起请求。
5. 　　服务器处理请求，浏览器接收HTTP响应。
6. 　　渲染页面，构建DOM树。
7. 　　关闭TCP连接（四次挥手）。





## 域名解析



先在浏览器缓存中找，如果没有就去操作系统看看有没有缓存，如果没有再去hosts文件看，如果还没有，找不到就去本地DNS解析器缓存中找，如果还是找不到就迭代查询

依次到       根域名服务器 --->  顶级域名服务器（.cn./cm）-->     权限域名服务器（baidu.com）   去寻找



## HTTP发起请求

域名解析后，TCP三次握手进行连接，连接结束后开始发送HTPP请求报文



请求报文由请求行（request line）  请求头（header） 请求体





## 服务器处理请求并返回HTTP报文

服务器在收到浏览器发送的HTTP请求之后，会将收到的HTTP报文封装成HTTP的Request对象，并通过不同的Web服务器进行处理，处理完的结果以HTTP的Response对象返回，主要包括状态码，响应头，响应报文三个部分。



响应报文由响应行(request line)、响应头部(header)、响应主体三个部分组成。



 响应主体包含回车符、换行符和响应返回数据，并不是所有响应报文都有响应数据

## 页面渲染

　　如果说响应的内容是HTML文档的话，就需要浏览器进行解析渲染呈现给用户。整个过程涉及两个方面：解析和渲染。在渲染页面之前，需要构建DOM树和CSSOM树。



浏览器解析渲染页面分为一下五个步骤：

- 根据 HTML 解析出 DOM 树
- 根据 CSS 解析生成 CSS 规则树
- 结合 DOM 树和 CSS 规则树，生成渲染树
- 根据渲染树计算每一个节点的信息
- 根据计算好的信息绘制页面



## 总结图



![img](../../images/%E8%AE%A1%E7%BD%91/70.png)



# IP协议

详情：https://mp.weixin.qq.com/s/yAlErlC09GnjaVvwUo3Acg









# 网络安全



## DNS劫持

DNS劫持即域名劫持，是通过将原域名对应的IP地址进行替换，从而使用户访问到错误的网站，或者使用户无法正常访问网站的一种攻击方式。





域名劫持往往只能在特定的网络范围内进行，范围外的DNS服务器能够返回正常的IP地址。攻击者可以冒充原域名所属机构，通过电子邮件的方式修改组织机构的域名注册信息，或者将域名转让给其它主持，并将新的域名信息保存在所指定的DNS服务器中，从而使用户无法对原域名来进行解析以访问目标地址。



### **怎么应对DNS劫持？**



- 直接通过IP地址访问网站，避开DNS劫持
- 由于域名劫持往往只能在特定的网络范围内进行，因此一些高级用户可以通过网络设置让DNS指向正常的域名服务器以实现对目标网址的正常访问，例如计算机首选DNS服务器的地址固定为8.8.8.8。





## CSRF 攻击



CSRF，跨站请求伪造（英文全称是 Cross-site request forgery），是一种挟持用户在当前已登录的 Web 应用程序上执行非本意的操作的攻击方法。



**例子**

![图片](../../images/%E8%AE%A1%E7%BD%91/640-16556243638618.png)

> 1. 用户登陆银行，没有退出，浏览器包含了 用户 在银行的身份认证信息。
> 2. 攻击者将伪造的转账请求，包含在在帖子
> 3. 用户在银行网站保持登陆的情况下，浏览帖子
> 4. 将伪造的转账请求连同身份认证信息，发送到银行网站
> 5. 银行网站看到身份认证信息，以为就是 用户的合法操作，最后造成用户资金损失。



### **怎么应对 CSRF 攻击呢？**

- **检查 Referer 字段**

  HTTP头中的Referer字段记录了该 HTTP 请求的来源地址。在通常情况下，访问一个安全受限页面的请求来自于同一个网站，而如果黑客要对其实施 CSRF攻击，他一般只能在他自己的网站构造请求。因此，可以通过验证Referer值来防御CSRF 攻击。

- **添加校验 token**

  以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有token或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。

- **敏感操作多重校验**

  对一些敏感的操作，除了需要校验用户的认证信息，还可以通过邮箱确认、验证码确认这样的方式多重校验。



## DoS、DDoS、DRDoS 攻击



- **DOS**: (Denial of Service), 翻译过来就是拒绝服务, 一切能引起拒绝 行为的攻击都被称为 DOS 攻击。最常见的 DoS 攻击就有**计算机网络宽带攻击**、**连通性攻击**。

- **DDoS**: (Distributed Denial of Service)，翻译过来是分布式拒绝服务。是指处于不同位置的多个攻击者同时向一个或几个目标发动攻击，或者一个攻击者控制了位于不同位置的多台机器，并利用这些机器对受害者同时实施攻击。

  主要形式有流量攻击和资源耗尽攻击，常见的 DDoS攻击有：**SYN Flood、Ping of Death、ACK Flood、UDP Flood** 等。

- **DRDoS**: (Distributed Reflection Denial of Service)，中文是分布式反射拒绝服务，该方式靠的是发送大量带有被害者 IP 地址的数据包给攻击主机，然后攻击主机对 IP 地址源做出大量回应，从而形成拒绝服务攻击。





### 

### **如何防范DDoS?**

> 针对DDoS中的流量攻击，最直接的方法是增加带宽，理论上只要带宽大于攻击流量就可以了，但是这种方法成本非常高。在有充足带宽的前提下，我们应该尽量提升路由器、网卡、交换机等硬件设施的配置。
>
> 针对资源耗尽攻击，我们可以升级主机服务器硬件，在网络带宽得到保证的前提下，使得服务器能够有效对抗海量的SYN攻击包。我们也可以安装专业的抗DDoS防火墙，从而对抗SYN Flood等流量型攻击。瓷碗，负载均衡，CDN等技术都能有效对抗DDos攻击。



## XSS 攻击



XSS 攻击也是比较常见，XSS，叫**跨站脚本攻击（Cross-Site Scripting）**，因为会与层叠样式表 (Cascading Style Sheets, CSS) 的缩写混淆，因此有人将跨站脚本攻击缩写为 XSS。它指的是恶意攻击者往 Web 页面里插入恶意 html 代码，当用户浏览网页的时候，嵌入其中 Web 里面的 html 代码会被执行，从而达到恶意攻击用户的特殊目的。





简单说，XSS的攻击方式就是想办法“教唆”用户的浏览器去执行一些这个网页中原本不存在的前端代码









### 举例

![图片](../../images/%E8%AE%A1%E7%BD%91/640-165562451036110.png)

> 反射型举个例子吧，流程图如下：
>
> 1. 攻击者构造出特殊的 URL，其中包含恶意代码。
> 2. 用户打开带有恶意代码的 URL 时，访问正常网站服务器
> 3. 网站服务端将恶意代码从 URL 中取出，拼接在 HTML 中返回给浏览器。
> 4. 用户浏览器接收到响应后解析执行，混在其中的恶意代码也被执行，请求恶意服务器，发送用户数据
> 5. 攻击者就可以窃取用户的数据，以此冒充用户的行为，调用目标网站接口执行攻击者指定的操作。





### **如何应对 XSS 攻击？**



- 对输入进行过滤，过滤标签等，只允许合法值。
- HTML 转义
- 对于链接跳转，如`<a href="xxx"` 等，要校验内容，禁止以 script 开头的非法链接。
- 限制输入长度





















## RSA和AES算法有什么区别



- **RSA**

  采用非对称加密的方式，采用公钥进行加密，私钥解密的形式。其私钥长度一般较长，由于需要大数的乘幂求模等运算，其运算速度较慢，不合适大量数据文件加密。

- **AES**

  采用对称加密的方式，其秘钥长度最长只有256个比特，加密和解密速度较快，易于硬件实现。由于是对称加密，通信双方在进行数据传输前需要获知加密密钥。



























# 计网面试点

**网关IP地址和IP地址的区别**

https://www.php.cn/faq/461404.html





# 接口请求的全流程





先dns解析出IP ，然后建立tcp连接 封装http报文tcp报文IP报文 mac报文 经过网卡发送到路由器走到交换机 找到服务端路由器 再找到服务器 服务端再解析报文 解析出http请求 调用接口 层层封装返回数据和渲染的视图 再经过上面的流程返回给客户端？













# Ping的作用是什么

PING 主要的作用就是**测试在两台主机之间能否建立连接**，如果 PING 不通就无法建立连接。



它其实就是向目的主机发送多个 ICMP 回送请求报文

- 如果没有响应则无法建立连接
- 如果有响应就可以根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包**往返时间及丢包率**







# HTTP变化历程



## HTTP1.1 和 HTTP1.0 的区别有哪些？

![image-20220917171545699](../../images/%E8%AE%A1%E7%BD%91/image-20220917171545699.png)

- 1.**长链接**

- - 早期 HTTP1.0 的每一次请求都伴随着一次三次握手的过程，并且是**串行的请求**，增加了不必要的性能开销
  - HTTP1.1 **新增了长链接**的通讯方式，减少了性能损耗

- 2.**管道**

- - HTTP1.0 只有串行发送，没有管道
  - HTTP1.1 增加了**管道**的概念，使得在同一个 TCP 链接当中可以同时发出多个请求

- 3.**断点续传**

- - HTTP1.0 **不支持断点续传**
  - HTTP1.1 新增了 **range** 字段，用来指定数据字节位置，开启了断点续传的时代

- 4.**Host头处理**

- - HTTP1.0 任务主机只有一个节点，所以并**没有传 HOST**
  - HTTP1.1 时代，虚拟机技术越来越发达，一台机器上也有可能有很多节点，故**增加了 HOST 信息**

- 5.**缓存处理**

- - 在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准
  - HTTP1.1则**引入了更多的缓存控制策略**例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。

- 6.**错误状态响应码**

- - 在HTTP1.1中**新增了24个错误状态响应码**，如410（Gone）表示服务器上的某个资源被永久性的删除等。



### 总结：

- 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。





> 在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。
>
> 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：
>
> ```makefile
> Connection:keep-alive
> ```
>
> 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。
>
> HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。









## HTTPS 和 HTTP 的区别是什么？

![image-20220917171601111](../../images/%E8%AE%A1%E7%BD%91/image-20220917171601111.png)





- 1.**SSL安全协议**

- - HTTP 是超⽂本传输协议，信息是**明⽂传输**，存在安全⻛险的问题。
  - HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够**加密传输**。

- 2.**建立连接**

- - HTTP 连接建⽴相对简单， TCP **三次握⼿**之后便可进⾏ HTTP 的报⽂传输。
  - HTTPS 在 TCP **三次握⼿**之后，还需进⾏ **SSL/TLS** 的**握⼿**过程，才可进⼊加密报⽂传输。

- 3.**端口号**

- - HTTP 的端⼝号是 **80**。
  - HTTPS 的端⼝号是 **443**。

- 4.**CA证书**

- - **HTTPS 协议需要向 CA（证书权威。机构）申请数字证书**来保证服务器的身份是可信的。











## HTTP2 和 HTTP1.1 的区别是什么？



![image-20220917171619563](../../images/%E8%AE%A1%E7%BD%91/image-20220917171619563.png)



- 1.**头部压缩**

- - 在 HTTP2 当中，如果你发出了**多个请求**，并且它们的**头部(header)是相同的**，那么 HTTP2 协议会帮你**消除同样的部分**。(其实就是在客户端和服务端维护一张索引表来实现)

- 2.**二进制格式**

- - HTTP1.1 采用**明文**的形式
  - HTTP/2 全⾯采⽤了**⼆进制格式**，头信息和数据体都是⼆进制

- 3.**数据流**

- - HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。(对数据包做了标记，标志其属于哪一个请求，其中规定客户端发出的数据流编号为奇数，服务器发出的数据流编号为偶数。**客户端还可以指定数据流的优先级**，优先级⾼的请求，服务器就先响应该请求)

- 4.**IO多路复用**

- - 如:在⼀个连接中，服务器收到了客户端 A 和 B 的两个请求，但是发现在处理 A 的过程中⾮常耗时，索性就先回应 A 已经处理好的部分，再接着回应 B 请求，最后再回应 A 请求剩下的部分。
  - HTTP/2 可以**在⼀个连接中并发多个请求或回应**。

- 5.**服务器推送**

- - 服务器可以主动向客户端发送请求



![image-20220917192535200](../../images/%E8%AE%A1%E7%BD%91/image-20220917192535200.png)





















### 自己理解

http1的管道化技术，只是可以不用等待响应就能连续发多个http请求





但是接收方的队头阻塞问题没有解决，是一条hhtp请求消息处理完之后才能继续处理下一个消息





但是http2解决了接收方队头阻塞问题，基于多路复用可以同时处理多个请求。（多路复用，同一个TCP连接，**使用一个连接并行发送多个请求和响应**，http1不能同时发送多个响应）





帧是数据传输的最小单位，。流可以承载双向消息，每个流都有一个唯一的整数 ID









## HTTP3 和 HTTP2 的区别是什么

![image-20220917171636911](../../images/%E8%AE%A1%E7%BD%91/image-20220917171636911.png)

- 1.**协议不同**

- - HTTP2 是基于 **TCP** 协议实现的
  - HTTP3 是基于 **UDP** 协议实现的

- 2.**QUIC**

- - **HTTP3 新增了 QUIC 协议**来实现可靠性的传输

- 3.**握手次数**

- - HTTP2 是基于 HTTPS 实现的，建立连接需要先进行 TCP 3次握手，然后再进行 TLS 3次握手，**总共6次握手**
  - HTTP3 只需要 QUIC 的**3次握手**





## http变化历程总结（重点）





**http1.1**比**http1.0**,取消短连接，改为**长连接**，**不需要**一个http响应完就断开连接，下次请求再建立。



**http1.1**还有，提供管道化传输数据，没有管带化传输数据之前，发送方必须等上一次请求的响应回来之后才能发送下一个http请求，但是管道化传输之后，就可以不用等待上一个请求的响应，可以连续发送多个请求。





（如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为队头堵塞），**http1.1**的管道化传输解决了**请求的队头阻塞，但是没有解决响应的队头阻塞**。如果某个请求因为某种原因被阻塞时，在后面排队的请求也一并被阻塞，会导致客户端一直等待不到响应数据的返回。**哪个请求先到达就先处理哪个请求并响应，如果这个请求的响应因为某种原因阻塞了，后面的响应都会阻塞。**



**PS:在HTTP1.x中，并发多个请求需要多个TCP连接**

**http2.0**相比于**http1.1,**数据不再采用明文传输，而采用二进制格式传输。而且在http1.1中，并发多个请求需要多个TCP连接，而http2中，可以单个TCP连接并发处理http请求和响应（这样解决了http1.1.中的响应队头阻塞，因为可以这个如果当前响应比较慢，或者比较耗费时间，可以转而去处理其他请求的响应。）



（单个TCP怎样解决并发，HTTP/2 引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接）





PS：HTTP解决了HTTP1队头阻塞的问题，但是TCP层面的队头阻塞没有解决。





**http3.0**相比于http之前







HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是**一旦发生丢包，就会阻塞住所有的 HTTP 请求**，这属于 TCP 层队头阻塞。



HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**





UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。





> 之前客户端发送请求服务端必须处理了它的响应 客户端才能发送下一个请求 但是http2.0是每个请求和响应带有一个stream标识 多个stream之间是可以并发传输的  也就是说服务端处理请求1的响应的时候 也可以处理请求2的响应 并发传输请求12的响应  由于有了stream标识 就可以并发传输啦



### TCP队头阻塞



如果低序列报文在传输过程中丢失了，那么即使发送的高序列报文（也就是低序列报文后发的报文）到了，也不能被HTTP应用层使用，发生了队头阻塞，必须得等丢失的数据包发送过来才能被HTTP层使用。













